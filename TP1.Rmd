---
title: "tp1"
author: "GroupeB"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r importation-librairies, include=FALSE}
library(tidyverse)
library(skimr)
library(dplyr)
library(readr)
library(rsample)
library(knitr)
library(lubridate)
```

```{r importation-des-fonctions, include=FALSE}
source("plot_distribution.R")
#file.exists("outliers.R")
#file.exists("plot_distribution.R")
```


## Introduction : 

Dans un contexte où les menaces informatiques se multiplient et évoluent rapidement, les centres d’opérations de sécurité (SOC) doivent être en mesure de détecter, classifier et répondre efficacement aux incidents de cybersécurité. Pour améliorer ces processus, Microsoft a développé la base de données GUIDE, qui constitue la plus grande collection publique d'incidents réels de sécurité. Cette base de données a été mise en place dans le cadre du développement du Copilot for Security Guided Response (CGR) et a pour objectif principal d’améliorer l’enquête, le triage et l’assainissement des incidents de sécurité.

**Problème rencontré :** La base de donnée fournie a **4147992** observations et 46 variables, soit 45 potentielles variables explicatives. Ceci a soulevé deux problèmes majeurs dans le cadre de notre travail :

**Problème1** : Le fichier est trop lourd ; il pèse plus d'un GigaOctet, ce qui ralentit les algorithmes de Machine learning, puisque nous n'avons pas accès aux super-calculateurs. Pour contourner cet obstacle, nous avons selectionné un échantillon de 25 000 observations que nous avons renommé df. Tout notre travail est basé sur cette nouvelle database. Mais l'exécution final s'est faite sur la BD originale

**Problème2** : En présence d'autant de variables cibles et d'autant d'observations, il y a un risque de surapprentissage.
Donc nous allons préter une attention particulière à la colinéarité entre les différentes variables. Et via une analyse par composantes principales, on pourra selectionner les prédicteurs les plus pertinents.




#```{r importation-du-dataset,include = FALSE}
#df<- read.csv("./data/GUIDE_Train.csv")
#head(df)
#View(df)
#```



#```{r ecriture-du-dataset-de-travail, include = FALSE}
#set.seed(123)  
#df_subset <- df %>%
#sample_n(25000)
#write_csv(df_subset, "data_subset.csv")
#```



```{r importation-du-dataset, include=FALSE}
df<- read.csv("data_subset.csv")
df[df == ""] <- NA  
df[df == " "] <- NA 
df[df %in% c("NA", "N/A", "NULL", "#N/A")] <- NA 
head(df)
#View(df)
```


### 1. Méthodologie : 

1. A propos des donnees :

    1.1 importation et source des données (À propos de l'auteur) ;
    
    1.2 Description des variables ;
    
      * Variable cible,
      
      * Variables explicatives
      
    1.3 Gestion des valeurs manquantes ;
    
    1.4 gestion des valeurs manquantes ;
    
2. Visualisations sur l'ensemble de test :

    2.1 Les diagramme en barres ;
    
    2.2 
    
    
3. Regression logistique

    
### 1. A propos des donnees
####  1.1 À propos de l'auteur ;

Cette base de données est accessible en libre téléchargement via kagle(https://www.kaggle.com/datasets/Microsoft/microsoft-security-incident-prediction?select=GUIDE_Train.csv).

Les auteurs sont : 

Microsoft (Propriétaire)

Scott Freitas (Administrateur)

amirh gharib (Editeur)

Rob McCann (Editeur)

Jovan Kalajdjieski (Editeur).

cette base englobe plus de 13 millions d'éléments de preuve sur 33 types d'entités, dont 1,6 million d'alertes et 1 million d'incidents annotés avec des étiquettes de triage provenant de clients sur une période de deux semaines. Cette télémétrie a été collectée auprès des clients Microsoft Defender XDR, englobant divers produits tels que des terminaux, des périphériques réseau, des environnements cloud, des systèmes de messagerie, etc.
(pris dans le site de l'auteur)
  
####  1.2 Description des variables :


##### **La Variable cible** : IncidentGrade : (La gravité de l'incident).

  Cette variables va nous aider à identifier la gravité des différents incidents.
  
##### **Variables explicatives potentielles** :

**Id** : Identifiant unique pour chaque paire OrgId-IncidentId.

**OrgId** : Identifiant de l'organisation.

**IncidentId** : Identifiant unique de l'incident au sein de l'organisation.

**AlertId** : Identifiant unique pour une alerte.

**Timestamp** : Date et heure de création de l’alerte.

**DetectorId** : Identifiant unique du détecteur ayant généré l’alerte.

**AlertTitle** : Titre de l’alerte.

**Category** : Catégorie de l’alerte.

**MitreTechniques** : techniques d'attaque qui ont été identifiées dans une alerte de sécurité, basées sur le framework MITRE ATT&CK.

**IncidentGrade** : Niveau de gravité attribué à l’incident par le SOC.

**ActionGrouped** : Action de remédiation de l’alerte par le SOC (niveau général).

**ActionGranular** : Action de remédiation de l’alerte par le SOC (niveau détaillé).

**EntityType** : Type d’entité impliquée dans l’alerte.

**EvidenceRole** : Rôle de la preuve dans l’enquête.

**DeviceId** : Identifiant unique du dispositif.

**Sha256** : Empreinte SHA-256 du fichier.

**IpAddress** : Adresse IP impliquée.

**Url** : URL impliquée.

**AccountSid** : Identifiant du compte on-premises.

**AccountUpn** : Identifiant du compte email.

**AccountObjectId** : Identifiant du compte Entra ID.

**AccountName** : Nom du compte on-premises.

**DeviceName** : Nom du dispositif.

**NetworkMessageId** : Identifiant au niveau organisationnel pour le message email.

**EmailClusterId** : Identifiant unique du cluster d’emails.

**RegistryKey** : Clé de registre impliquée.

**RegistryValueName** : Nom de la valeur du registre.

**RegistryValueData** : Données de la valeur du registre.

**ApplicationId** : Identifiant unique de l’application.

**ApplicationName** : Nom de l’application.

**OAuthApplicationId** : Identifiant de l’application OAuth.

**ThreatFamily** : Famille de logiciels malveillants associée à un fichier.

**FileName** : Nom du fichier.

**FolderPath** : Chemin du dossier contenant le fichier.

**ResourceIdName** : Nom de la ressource Azure.

**ResourceType** : Type de ressource Azure.

**Roles** : Métadonnées supplémentaires sur le rôle de la preuve dans l’alerte.

**OSFamily** : Famille du système d’exploitation.

**OSVersion** : Version du système d’exploitation.

**AntispamDirection** : Direction du filtre antispam.

**SuspicionLevel** : Niveau de suspicion.

**LastVerdict** : Verdict final de l’analyse de la menace.

**CountryCode** : Code du pays où la preuve a été trouvée.

**State** : État où la preuve a été trouvée.

**City** : Ville où la preuve a été trouvée.

Les variables sont réparties en 31 numériques et 15 catégorielles.

Mais, en réalité,les variables numérique sont en fait des id et des codes, Donc ce sont des facteurs à 
proprement parler.

Ces variables vont être utilisées pour prédire les anomalies et détecter des attaques


Nous constatons qu'il ya beaucoup de colonnes qui doivent être supprimées par ce que
Ce sont des Id --> Elles sont facilement identifiablesde façon unique et donc,
non performants pour les algorithmes d'apprentissage machine ;

```{r ensemble-train-test,include=FALSE}
set.seed(165)
split <- initial_split(df, prop = 0.8)
df_train <- training(split)
df_test <- testing(split)

```

#####  **Supression des colonnes non pertinentes pour l'étude** 

```{r suppression-colonnes-id}
col_a_supprimer = c("Id", "OrgId" ,"IncidentId","AlertId","DetectorId" ,
                    "DeviceId","AccountSid","AccountObjectId",
                    "NetworkMessageId","EmailClusterId","ApplicationId",
                    "OAuthApplicationId","ResourceIdName")
for (colonne in col_a_supprimer){
  df_train[[colonne]] <- NULL
}
```
Bien qu'elle identifient la données,

* Les variables "AccountUpn" et "AccountName" sont conservées par ce que, bien qu'étant des failles 
d'identification, elles rapportent des analyses sur les comptes utilisateurs,ce qui pourrait permettre de comprendre
la fraude.

* "DeviceName" a été conservé pour effectuer une analyse sur les attaques récurrentes sur certains appareils.

* On conserve "FileName" et "Sha256" pour tenir compte des fichiers malveillants récurrents.

```{r valeurs-manquantes}
valeurs_manquantes <- colSums(is.na(df_train))
pourcentage_nan <- (valeurs_manquantes / nrow(df_train)) * 100
valeurs_manquantes <- data.frame(
  Column = names(valeurs_manquantes),
  Missing_Values = valeurs_manquantes,
  Pourcentage_NaN = pourcentage_nan
) %>%
  filter(Pourcentage_NaN > 0) %>%
  arrange(desc(Pourcentage_NaN))
print(valeurs_manquantes)
```
* On va supprimer les colonnes "ActionGrouped", "ActionGranular", "ResourceType",
"ThreatFamily","AntispamDirection", "Roles"

```{r suspicionLevel, include=FALSE}
df_train %>%
  count(SuspicionLevel, sort = TRUE)
```


Dans cette colonne, la valeur manquante  signifie que la transaction est non suspecte ou
non évaluée. 


```{r LastVerdict, include= FALSE}
df_train %>%
  count(LastVerdict, sort = TRUE)
```
La valeur manquante signifie qu'il n'y a pas encore de verdict, ou que le verdict est inconnu



```{r MitreTechniques, include=FALSE}
df_train %>%
  count(MitreTechniques, sort = TRUE)
```

On va remplacer les valeurs manquantes par "Unknown"



```{r gestion-des-nan, include=FALSE}
col_a_supprimer = c("ActionGrouped","ActionGranular","ResourceType","ThreatFamily",
             "AntispamDirection", "Roles")
for (col in  col_a_supprimer){
  df_train[[col]] <- NULL
}

df_train$SuspicionLevel[is.na(df_train$SuspicionLevel)] <- "Not Suspicious"
df_train$LastVerdict[is.na(df_train$LastVerdict)] <- "Pending Analysis"
df_train$MitreTechniques[is.na(df_train$MitreTechniques)] <- "Unknown"
```



```{r statistiques,include=FALSE}
skim(df_train) %>%
  kable()
```

Plusieurs colonnes ne sont pas dans le bon type, on va les transformer.
Notons déjà que toutes les colonnes numériques devraient etre categorielles

```{r changement-type-colonnes, include= FALSE}
df_train$Timestamp <- as.Date(df_train$Timestamp, format = "%Y-%m-%d")


df_train <- df_train %>%
  mutate(across(where(is.numeric), as.factor),
         across(where(is.character), as.factor))
```

### 2. Visualisation

```{r visualisation-mitre-technique}

technique_counts <- df_train %>%
  group_by(MitreTechniques) %>%
  summarise(Count = n())

techniques_ordone <- technique_counts %>%
  arrange(desc(Count))

ggplot(data = head(techniques_ordone, 10), 
       aes(y = fct_reorder(MitreTechniques, Count), x = Count)) +
  geom_bar(stat = "identity", fill = "steelblue") + 
  labs(
    title = "MITRE Techniques Top10",
    x= " ",
    y  = " "
  ) +
  theme_minimal() 
```
**interprétation** : 


```{r incident-Grade-visualisation}
IncidentGrade_count <- df_train %>%
  group_by(IncidentGrade) %>%
  summarise(Count = n()) 

ggplot(data = IncidentGrade_count, 
       aes(x = fct_reorder(IncidentGrade, Count), y = Count)) +  
  geom_bar(stat = "identity", fill = "steelblue") + 
  labs(
    title = "Distribution des Incident Grades",
    x = "Incident",
    y = " "
  ) +
  theme_minimal()
 view(df_train)
```
**Interpretation** :  Le nombre élevé de BenignPositive et FalsePositive indique que le système génère beaucoup d'alertes inutiles (bruit).Ce qui est contre productif.
Une première recommandation est déjà d'e rafinner d'améliorer le système d'alerte pour qu'il capte moin de bruit.


```{r repartition-categories}

category_counts <- df_train %>%
  count(Category, name = "Count") %>%
  arrange(desc(Count))

top_5_categories <- category_counts %>% slice(1:5)
autres_count <- sum(category_counts$Count) - sum(top_5_categories$Count)

top_5_categories <- top_5_categories %>%
  add_row(Category = "Autres", Count = autres_count)

ggplot(top_5_categories, aes(x = "", y = Count, fill = fct_reorder(Category, -Count))) +
  geom_bar(stat = "identity", width = 1) +
  coord_polar(theta = "y", start = 0) + 
  labs(title = "Distribution des Catégories") +
  theme_void() +
  scale_fill_viridis_d() 

```
```{r IncidentGrade-fill-selon-IncidentGrade}

```

**interpretation** 


```{r IncidentGrade-fill-selon-EntityType}

```
**interpretation**


```{r IncidentGrade-fill-selon-SuspicionLevel}

```
**interpretation**


```{r IncidentGrade-fill-selon-Usage}

```
**interpretation**



```{r IncidentGrade-evolution-dans-le-temps}

incident_grade_monthly <- df_train %>%
  mutate(Month = floor_date(Timestamp, "month")) %>%
  group_by(Month, IncidentGrade) %>%
  summarise(Count = n(), .groups = 'drop')

# Graphique de l'évolution des IncidentGrade dans le temps
ggplot(incident_grade_monthly, aes(x = Month, y = Count, color = IncidentGrade)) +
  geom_line(size = 1) +
  labs(
    title = "Évolution de IncidentGrade dans le Temps",
    x = "Mois",
    y = "Nombre d'Incidents",
    color = "IncidentGrade"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
**interpretation** On remarque que les déclarations d'incidents sont stables durant l'hivers.
C'est en mai et Juin que se dégagent la majorité des signalements. Possible lien avec 
tous les mouvements qui se déroulent durant l'été ? c'est une question qu'il faudra explorer.

Faisons un zoom sur les fluxtuations pendant le mois de mai




```{r incidents-mai}
start_date <- as.Date("2024-05-01")
end_date <- as.Date("2024-08-30")

filtered_data <- df_train %>%
  filter(Timestamp >= start_date & Timestamp <= end_date)

daily_counts <- filtered_data %>%
  group_by(Date = Timestamp) %>%
  summarise(Count = n(), .groups = "drop")

ggplot(daily_counts, aes(x = Date, y = Count)) +
  geom_line(color = "skyblue", size = 1) +
  geom_point(color = "skyblue") +
  labs(
    title = paste("Number of Incidents from", format(start_date, "%B %Y"), "to", format(end_date, "%B %Y")),
    x = "Date",
    y = "Numbre d'ncidents"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_x_date(date_breaks = "7 days", date_labels = "%d-%b") +
  geom_hline(yintercept = mean(daily_counts$Count), linetype = "dashed", color = "red")


```

**Interprétation**



### 3. Regression logistique

